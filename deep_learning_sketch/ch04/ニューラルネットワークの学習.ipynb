{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 データから学習する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ニューラルネットワークの特徴は「プログラムがデータから自動的に学習する」ということ。  \n",
    "具体的には「プログラムはデータから重みパラメータの値を自動的に更新」して学習を実行する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 損失関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 プログラムは何を指標として、重みパラメータを更新しているのか?\n",
    "\n",
    "ニューラルネットワークの学習は「損失関数」を指標として、損失関数の値が小さくなるように重みパラメータを更新する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 二乗和誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失関数として、最も有名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{ \\displaystyle\n",
    "E = \\frac{1}{2} \\sum_k {(y_k-t_k)}^2}\n",
    "\\tag{4.1} \\label{4.1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ykはニューラルネットワークの出力、tkは教師データを表し、kはデータの次元数を表す。   \n",
    "* ニューラルネットワークの出力と正解となる教師データの各要素の差の2乗の総和が2乗和誤差。   \n",
    "* 出力結果の教師データの誤差が小さい場合，より小さい値を出力する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "二乗和誤差を実装\n",
    "\"\"\"\n",
    "def mean_squared_error(y, t):\n",
    "    return 0.5*np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正解を2とする\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# パターン1：「2」の割合が最も高い場合\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# パターン2：「7」の割合が最も高い場合\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パターン1の方がパターン2よりも二乗和誤差関数を実装した結果が小さい。  \n",
    "つまり、パターン1の方が出力結果が教師データにより適合していることを二乗和誤差関数が示している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 交差エントロピー誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{ \\displaystyle\n",
    "E = - \\sum_k t_k \\log y_k}\n",
    "\\tag{4.2} \\label{4.2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tkは2乗和誤差と同様教師データであり、one-hot表現であるため、   \n",
    "(4.2)は実質的には正解ラベルが1に対応する出力の自然対数を計算するだけになっている。   \n",
    "ここで、自然対数のグラフは次のようになっている。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "交差エントロピー誤差を実装\n",
    "\"\"\"\n",
    "def cross_entropy_error(y, t):\n",
    "     delta = 1e-7    #np.log(0)防止\n",
    "     return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正解を2とする\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# パターン1：「2」の割合が最も高い場合\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# パターン2：「7」の割合が最も高い場合\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解ラベルに対応する出力の値が大きいほど、交差エントロピー誤差は0に近づいている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 数値微分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 勾配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 学習アルゴリズムの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 機械学習で使用するデータセットは訓練データとテキストデータに分けて使用する。    \n",
    "\n",
    "* 訓練データで学習を行い、学習したモデルの汎化能力をテストデータで評価する。    \n",
    "\n",
    "* ニューラルネットワークの学習は損失関数を指標として、損失関数の値が小さくなるように重みパラメータを更新する。  \n",
    "\n",
    "* 重みパラメータを更新する際には、重みパラメータの勾配を利用して、勾配方向に重みの値を更新する作業を繰り返す。  \n",
    "\n",
    "* 微小な値を与えたときの差分によって微分を求めることを数値微分という。  \n",
    "\n",
    "* 数値微分によって、重みパラメータの勾配を求めることが出来る。  \n",
    "\n",
    "* 数値微分による計算には時間がかかるが、その実装は簡単である。   \n",
    "  一方、次章で実装するやや複雑な誤差逆伝播法は、高速に勾配を求めることが出来る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
