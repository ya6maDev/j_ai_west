{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 データから学習する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ニューラルネットワークの特徴は「プログラムがデータから自動的に学習する」ということ。  \n",
    "具体的には「プログラムはデータから重みパラメータの値を自動的に更新」して学習を実行する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 損失関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 プログラムは何を指標として、重みパラメータを更新しているのか?\n",
    "\n",
    "ニューラルネットワークの学習は「損失関数」を指標として、損失関数の値が小さくなるように重みパラメータを更新する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 二乗和誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失関数として、最も有名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{ \\displaystyle\n",
    "E = \\frac{1}{2} \\sum_k {(y_k-t_k)}^2}\n",
    "\\tag{4.1} \\label{4.1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ykはニューラルネットワークの出力、tkは教師データを表し、kはデータの次元数を表す。   \n",
    "* ニューラルネットワークの出力と正解となる教師データの各要素の差の2乗の総和が2乗和誤差。   \n",
    "* 出力結果の教師データの誤差が小さい場合，より小さい値を出力する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "二乗和誤差を実装\n",
    "\"\"\"\n",
    "def mean_squared_error(y, t):\n",
    "    return 0.5*np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正解を2とする\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# パターン1：「2」の割合が最も高い場合\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# パターン2：「7」の割合が最も高い場合\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パターン1の方がパターン2よりも二乗和誤差関数を実装した結果が小さい。  \n",
    "つまり、パターン1の方が出力結果が教師データにより適合していることを二乗和誤差関数が示している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 交差エントロピー誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{ \\displaystyle\n",
    "E = - \\sum_k t_k \\log y_k}\n",
    "\\tag{4.2} \\label{4.2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tkは2乗和誤差と同様教師データであり、one-hot表現であるため、   \n",
    "(4.2)は実質的には正解ラベルが1に対応する出力の自然対数を計算するだけになっている。   \n",
    "ここで、自然対数のグラフは次のようになっている。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "交差エントロピー誤差を実装\n",
    "\"\"\"\n",
    "def cross_entropy_error(y, t):\n",
    "     delta = 1e-7    #np.log(0)防止\n",
    "     return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正解を2とする\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# パターン1：「2」の割合が最も高い場合\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# パターン2：「7」の割合が最も高い場合\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解ラベルに対応する出力の値が大きいほど、交差エントロピー誤差は0に近づいている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 ミニバッチ学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 機械学習の問題は、訓練データを使って学習を行う。   \n",
    "具体的には訓練データに対する損失関数を求め、その値を出来るだけ小さくするようなパラメータを探索するということである。\n",
    "\n",
    "* 損失関数はすべての訓練データを対象として求める必要がある。(訓練データが100個あれば、100個の損失関数の和を求めて、指標とする)\n",
    "\n",
    "* ビックデータの全てに対して、損失関数を求めるのは現実的ではないので、データの中から一部をランダムに選び出す。   \n",
    "これをミニバッチという。そのミニバッチごとに学習を行うのが現実的であり、これをミニバッチ学習と言う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading train-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n",
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "#MNISTデータの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練データからランダムに10枚抜き出す\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "バッチ対応版 交差エントロピー誤差の実装\n",
    "\"\"\"\n",
    "def cross_entropy_error(y ,t):\n",
    "    if y.dim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "\n",
    "    batch_size = y.sahpe[0]\n",
    "    return -np.sum(t * np.log(y)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 数値微分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ニューラルネットワークの学習では、最適なパラメータ(重みとバイアス)を探索する際に、   \n",
    "損失関数の値が出来るだけ小さくなるようにパラメータを探索する。   \n",
    "\n",
    "* 出来るだけ小さな損失関数の値を探すため、パラメータの微分(正確には勾配)を計算している。\n",
    "\n",
    "* 計算された微分の値を手がかりにパラメータの値を徐々に更新している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 微分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(編集中)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 勾配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(編集中)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 学習アルゴリズムの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 ニューラルネットワークの学習手順"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ステップ1 : 「ミニバッチ」\n",
    "\n",
    "訓練データの中からランダムに一部のデータを選び出す。その選ばれたデータをミニバッチと呼ぶ。   \n",
    "ここでは、そのミニバッチの損失関数を減らすことを目的とする。\n",
    "\n",
    "2. ステップ2 : 「勾配の算出」\n",
    "\n",
    "ミニバッチの損失関数を減らすために、各重みパラメータの勾配を求める。  \n",
    "勾配は、損失関数の値を最も減らす方向を示す。\n",
    "\n",
    "3. ステップ3 : 「パラメータの更新」\n",
    "\n",
    "重みパラメータを勾配方向に微小量だけ更新する。\n",
    "\n",
    "4. ステップ4 : 「繰り返す」\n",
    "\n",
    "ステップ1～ステップ3までを繰り返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.11236666666666667, 0.1135\n",
      "train acc, test acc | 0.7856, 0.7894\n",
      "train acc, test acc | 0.8756833333333334, 0.8798\n",
      "train acc, test acc | 0.8988333333333334, 0.9026\n",
      "train acc, test acc | 0.9087833333333334, 0.9119\n",
      "train acc, test acc | 0.91505, 0.9171\n",
      "train acc, test acc | 0.9183166666666667, 0.9213\n",
      "train acc, test acc | 0.9231666666666667, 0.9243\n",
      "train acc, test acc | 0.9263666666666667, 0.9269\n",
      "train acc, test acc | 0.9301166666666667, 0.9307\n",
      "train acc, test acc | 0.933, 0.9328\n",
      "train acc, test acc | 0.9357166666666666, 0.9361\n",
      "train acc, test acc | 0.9386166666666667, 0.9383\n",
      "train acc, test acc | 0.9402833333333334, 0.9399\n",
      "train acc, test acc | 0.9430833333333334, 0.9421\n",
      "train acc, test acc | 0.9452333333333334, 0.9446\n",
      "train acc, test acc | 0.9460833333333334, 0.9451\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000  # 繰り返しの回数を適宜設定する\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配の計算\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # パラメータの更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 機械学習で使用するデータセットは訓練データとテキストデータに分けて使用する。    \n",
    "\n",
    "* 訓練データで学習を行い、学習したモデルの汎化能力をテストデータで評価する。    \n",
    "\n",
    "* ニューラルネットワークの学習は損失関数を指標として、損失関数の値が小さくなるように重みパラメータを更新する。  \n",
    "\n",
    "* 重みパラメータを更新する際には、重みパラメータの勾配を利用して、勾配方向に重みの値を更新する作業を繰り返す。  \n",
    "\n",
    "* 微小な値を与えたときの差分によって微分を求めることを数値微分という。  \n",
    "\n",
    "* 数値微分によって、重みパラメータの勾配を求めることが出来る。  \n",
    "\n",
    "* 数値微分による計算には時間がかかるが、その実装は簡単である。   \n",
    "  一方、次章で実装するやや複雑な誤差逆伝播法は、高速に勾配を求めることが出来る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
