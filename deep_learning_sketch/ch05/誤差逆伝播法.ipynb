{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 誤差逆伝播法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 前章で学んだ数値微分はシンプルで実装が簡単だが、計算に時間がかかるという難点がある\n",
    "* 誤差逆伝播法は、重みパラメータの勾配の計算を効率良く行う手法である"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  連鎖律"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逆方向の伝播では「局所的な微分」を順方向とは逆方向に伝達します。  \n",
    "この「局所的な微分」を伝達する原理を連鎖律と呼びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "連鎖律とは、合成関数の微分についての性質であり、以下のように定義されている。   \n",
    "\n",
    "ある関数が合成関数で表される場合、その合成関数の微分は、   \n",
    "合成関数を構成するそれぞれの関数の微分の積によって表すことが出来る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.リンゴの例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記の図は「100円(消費税は10%)のりんごを2個買う」という問題を計算グラフで表している。\n",
    "\n",
    "順伝播：計算グラフの出発点から終着点への伝播   \n",
    "逆伝播：順伝播の逆の伝播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/apple.png\" title=\"リンゴ2個の買い物\" width=\"800\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple_price: 200\n",
      "price: 220\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dTax: 200\n"
     ]
    }
   ],
   "source": [
    "from layer_naive import *\n",
    "\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(\"apple_price:\", apple_price)\n",
    "print(\"price:\", int(price))\n",
    "print(\"dApple:\", dapple)\n",
    "print(\"dApple_num:\", int(dapple_num))\n",
    "print(\"dTax:\", dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誤差逆伝播法の勾配確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:3.849953962118686e-10\n",
      "b1:2.196574470314462e-09\n",
      "W2:5.659533362690474e-09\n",
      "b2:1.3925124024011248e-07\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "# ネットワークの定義\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 各重みの絶対誤差の平均を求める\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(key + \":\" + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逆誤差伝播法を使った学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ミニバッチで繰り返し学習（重み、バイアスの更新）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11653333333333334 0.1147\n",
      "0.8990666666666667 0.9015\n",
      "0.92235 0.926\n",
      "0.9344166666666667 0.9369\n",
      "0.9441666666666667 0.9429\n",
      "0.9502166666666667 0.9483\n",
      "0.9562333333333334 0.953\n",
      "0.9623166666666667 0.9602\n",
      "0.9635333333333334 0.9594\n",
      "0.9681333333333333 0.9644\n",
      "0.9700666666666666 0.9651\n",
      "0.9720666666666666 0.9661\n",
      "0.9741333333333333 0.9688\n",
      "0.9754833333333334 0.9675\n",
      "0.9752666666666666 0.9695\n",
      "0.9775333333333334 0.9706\n",
      "0.97955 0.9707\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "# ネットワークの定義\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 誤差逆伝播法によって、勾配を求める\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
